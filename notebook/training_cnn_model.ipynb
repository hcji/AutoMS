{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "106702f1",
   "metadata": {},
   "source": [
    "## CNN-based peak picking model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4e410e",
   "metadata": {},
   "source": [
    "This CNN peak picking model is used for comparison with AutoMS. The theory from [PeakOnly](https://pubs.acs.org/doi/10.1021/acs.analchem.9b04811) software, which takes the advantage of the\n",
    "intrinsic ability of CNN to classify peak with the profiles.\n",
    "\n",
    "Here we use the same training data as AutoMS for equitable evaluation. The training data are from [Schulze's study](https://www.mdpi.com/2218-1989/10/4/162). The manually picked true peaks are treated as positive samples. Since the negative samples are far more than the positives, we applied MSPD for choosing the worst peaks as negatives. Moreover, we also kept the number of positives and the negatives balanced. The hyper-parameter and the training details are described with the source codes bellow. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83774d87",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "523e4cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras import optimizers\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from AutoMS.mspd_original import peaks_detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600f2f40",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aaae740",
   "metadata": {},
   "source": [
    "We transformed the training data in advance, where X is the matrix of ROIs and Y is the corresponding labels. Here we load the data directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c94a50c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load('data/X.npy')\n",
    "y = np.load('data/Y.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d9a16d",
   "metadata": {},
   "source": [
    "Then, scale the intensity to 0 - 1, and remove the rows with all 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76cf25fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_14588\\1097894179.py:2: RuntimeWarning: invalid value encountered in true_divide\n",
      "  x[i,:] = x[i,:] / np.max(x[i,:])\n"
     ]
    }
   ],
   "source": [
    "for i in range(x.shape[0]):\n",
    "    x[i,:] = x[i,:] / np.max(x[i,:])\n",
    "\n",
    "sums = np.sum(x, axis = 1)\n",
    "keep = np.where(sums > 0)[0]\n",
    "x = x[keep, :]\n",
    "y = y[keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06d4ef5",
   "metadata": {},
   "source": [
    "Split the positive and negative samples with the labels and see how many of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab4510aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positives: 99474\n",
      "Number of negatives: 264116\n"
     ]
    }
   ],
   "source": [
    "pos = np.where(y == 1)[0]\n",
    "x_true = x[pos,:]\n",
    "print('Number of positives: {}'.format(len(x_true)))\n",
    "\n",
    "neg = np.where(y == 0)[0]\n",
    "x_false = x[neg,:]\n",
    "print('Number of negatives: {}'.format(len(x_false)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22962c1",
   "metadata": {},
   "source": [
    "Here, we use MSPD for detecting peaks in the negative samples. Only keep those samples failed to identified peaks with MSPD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a580809",
   "metadata": {},
   "outputs": [],
   "source": [
    "false = []\n",
    "for i in range(x_false.shape[0]): \n",
    "    pks, sigs, snrs_ = peaks_detection(x_false[i,:], np.arange(1, 30), 0)\n",
    "    criterion_1 = np.sum(x_false[i,:] == 0) < 5\n",
    "    if not criterion_1:\n",
    "        continue\n",
    "    snrs_.append(0)\n",
    "    criterion_2 = np.max(snrs_) <= 3\n",
    "    if criterion_2:\n",
    "        false.append(i)\n",
    "    if len(false) == 99474:\n",
    "        break\n",
    "false = np.array(false)\n",
    "x_false = x_false[false,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f48aca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of negatives: 68892\n"
     ]
    }
   ],
   "source": [
    "print('Number of negatives: {}'.format(len(x_false)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4585addf",
   "metadata": {},
   "source": [
    "He, we combine the processed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbffda51",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.vstack((x_true, x_false))\n",
    "y = np.array([1] * len(x_true) + [0] * len(x_false))\n",
    "y = np.vstack((y, 1-y)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73265e7f",
   "metadata": {},
   "source": [
    "### Define the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c56e375e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    def __init__(self, X, Y):\n",
    "        X = np.expand_dims(X, -1)\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        # train test split\n",
    "        self.X_tr, self.X_ts, self.Y_tr, self.Y_ts = train_test_split(X, Y, test_size=0.1)\n",
    "        \n",
    "        inp = Input(shape=(X.shape[1:]))\n",
    "        hid = inp\n",
    "        \n",
    "        # layer 1: filters: 32, kernel size: 2, activation: relu, padding: same, pooling size: 2\n",
    "        hid = Conv1D(32, kernel_size=2, activation='relu')(hid)\n",
    "        hid = MaxPooling1D(pool_size=2)(hid)\n",
    "        \n",
    "        # layer 2: filters: 16, kernel size: 2, activation: relu, padding: same, pooling size: 2   \n",
    "        hid = Conv1D(16, kernel_size=2, activation='relu')(hid)\n",
    "        hid = MaxPooling1D(pool_size=2)(hid)\n",
    "        \n",
    "        # layer 3: filters: 16, kernel size: 2, activation: relu, padding: same, pooling size: 2       \n",
    "        hid = Conv1D(16, kernel_size=2, activation='relu')(hid)\n",
    "        hid = MaxPooling1D(pool_size=2)(hid)\n",
    "        \n",
    "        # layer dense: nodes: 32, activation: relu\n",
    "        hid = Flatten()(hid)\n",
    "        hid = Dense(32, activation=\"relu\")(hid)\n",
    "        \n",
    "        # output layer for classification\n",
    "        prd = Dense(2, activation=\"softmax\")(hid)\n",
    "        \n",
    "        # optimizer: adam, loss function: categorical crossentropy\n",
    "        opt = optimizers.Adam(lr=0.001)\n",
    "        model = Model(inp, prd)\n",
    "        model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['acc'])\n",
    "        self.model = model\n",
    "    \n",
    "    def train(self, epochs=5):\n",
    "        self.model.fit(self.X_tr, self.Y_tr, validation_split= 0.1, epochs=epochs)\n",
    "    \n",
    "    def test(self):\n",
    "        Y_pred = np.round(self.model.predict(self.X_ts))\n",
    "        f1 = f1_score(self.Y_ts[:,0], Y_pred[:,0])\n",
    "        precision = precision_score(self.Y_ts[:,0], Y_pred[:,0])\n",
    "        recall = recall_score(self.Y_ts[:,0], Y_pred[:,0])\n",
    "        accuracy = accuracy_score(self.Y_ts[:,0], Y_pred[:,0])\n",
    "        return accuracy, precision, recall, f1\n",
    "    \n",
    "    def save(self, path):\n",
    "        self.model.save(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50498c19",
   "metadata": {},
   "source": [
    "### Training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f3bde1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\envs\\py38\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4262/4262 [==============================] - 25s 5ms/step - loss: 0.2393 - acc: 0.9066 - val_loss: 0.2144 - val_acc: 0.9181\n",
      "Epoch 2/10\n",
      "4262/4262 [==============================] - 20s 5ms/step - loss: 0.2121 - acc: 0.9206 - val_loss: 0.2089 - val_acc: 0.9222\n",
      "Epoch 3/10\n",
      "4262/4262 [==============================] - 20s 5ms/step - loss: 0.2060 - acc: 0.9233 - val_loss: 0.2060 - val_acc: 0.9234\n",
      "Epoch 4/10\n",
      "4262/4262 [==============================] - 20s 5ms/step - loss: 0.2036 - acc: 0.9244 - val_loss: 0.1993 - val_acc: 0.9275\n",
      "Epoch 5/10\n",
      "4262/4262 [==============================] - 20s 5ms/step - loss: 0.2005 - acc: 0.9253 - val_loss: 0.1992 - val_acc: 0.9267\n",
      "Epoch 6/10\n",
      "4262/4262 [==============================] - 20s 5ms/step - loss: 0.1994 - acc: 0.9261 - val_loss: 0.2018 - val_acc: 0.9265\n",
      "Epoch 7/10\n",
      "4262/4262 [==============================] - 19s 5ms/step - loss: 0.1981 - acc: 0.9265 - val_loss: 0.1951 - val_acc: 0.9281\n",
      "Epoch 8/10\n",
      "4262/4262 [==============================] - 19s 5ms/step - loss: 0.1969 - acc: 0.9265 - val_loss: 0.2016 - val_acc: 0.9265\n",
      "Epoch 9/10\n",
      "4262/4262 [==============================] - 20s 5ms/step - loss: 0.1955 - acc: 0.9271 - val_loss: 0.1946 - val_acc: 0.9306\n",
      "Epoch 10/10\n",
      "4262/4262 [==============================] - 19s 5ms/step - loss: 0.1945 - acc: 0.9273 - val_loss: 0.1933 - val_acc: 0.9288\n",
      "527/527 [==============================] - 1s 2ms/step\n",
      "accuracy: 0.9268872126863456\n",
      "precision: 0.9597238204833142\n",
      "recall: 0.9155688622754491\n",
      "f1: 0.9371265131007712\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN(x, y)\n",
    "cnn.train(epochs = 10)\n",
    "accuracy, precision, recall, f1 = cnn.test()\n",
    "\n",
    "print('accuracy: {}'.format(accuracy))\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('f1: {}'.format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36f2e75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn.save('model/cnn.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81775453",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
